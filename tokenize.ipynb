{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: sympy\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed sympy\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4266f9a03b44e39947cb5db018d268c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431207ffd1ca4d9c99327e20626d4249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5dec13f085243fab5d9ad72957a1ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b74221dd8b44b78b73331e321de9b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96369d5038354d39a58ec586f2349918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24fea4f68d1141bd9914be9b14aec7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\", use_fast=True)\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"FacebookAI/roberta-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the giant textfile in\n",
    "filepath = \"../home/schen9/dataset.txt\"\n",
    "\n",
    "def read_file(filepath,num_lines=850_000):\n",
    "    # text_lines = []\n",
    "    text = \"\"\n",
    "    with open(filepath) as fh:\n",
    "        for i, line in enumerate(fh):\n",
    "            if i >= num_lines:\n",
    "                break\n",
    "            # text_lines.append(line)\n",
    "            text += line\n",
    "    # return text_lines\n",
    "    return text\n",
    "\n",
    "text = read_file(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(text, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,   133,   735, 34546,    16,    10, 36248,   470,  8454,  4149,\n",
       "           822,     6,  3660,    30,  4720, 11998,     8,  8996,  4810,  1587,\n",
       "          1127,   338,     6,  1813, 11549,     6,     8,  4858,  8804,     4,\n",
       "         50118,   243,    21,   703,    30,  1234,   496, 12290,    15,   502,\n",
       "           262,     6, 36248,     4, 50118, 48812, 50118,  1620,  1602,    11,\n",
       "            10,   822,  4320,  1551,     6, 12602,   710,     6,  1354,     9,\n",
       "           407, 12336, 18095,   219,   859,     6,  4401,  4458,   988,  4436,\n",
       "             6,  1060,   275,  1441,  3884,   506, 10505, 15071,     6,  2730,\n",
       "             6, 25760,     6,     8, 33489,     6,    16,    67,    11,   657,\n",
       "            19,    69,     4, 50118,   894,  2215,    14, 12602,   710,  2997,\n",
       "           988,   396,   143,   657,    13,   123,     4, 50118,  1779, 12602,\n",
       "           710, 16766,     7,  1157,   123,     7,   989,   928,     6,    37,\n",
       "         11703,    14,    37,    34,    10,   778,     7,   339,    69,     4,\n",
       "         50118, 28886,   506, 10505,  3026,   988,    14,    37,    40,   339,\n",
       "            69,   409,    31,   123,   114,    37,    64,     4, 50118, 14009,\n",
       "             6,    67,     9,     5,  2706,    71,     5,   997,     6, 16766,\n",
       "             7, 39705,  1755, 12602,   710,    50,  2120,   143,  6132,  2857,\n",
       "            19,  3884, 20994,     4, 50118,   894,   423, 28411,   106,   561,\n",
       "            71,    79,    34,   174,   123,    14,    79,    34,  1613,     4,\n",
       "         50118, 28605,   889, 50118, 50118, 28917, 26481, 50118,  4688, 20044,\n",
       "          5780,     9,    20,   735, 34546,    16,  2034,    23,     5,  5672,\n",
       "             9,  1148,     8,     5,  4222,   824,    13,  6026,     8, 10112,\n",
       "          1624,     4, 50118,   133, 14692,  1468, 16755,   769,  2507,   112,\n",
       "            12,   176,     8,   204,    12,   406,     6,    19,     5,   371,\n",
       "         29078,  1716,     4, 50118, 49379, 50118, 50118, 47380,  5678, 50118,\n",
       "         50118, 36361,  4339,   716,    15,  1364,    30,   610,   272,  1536,\n",
       "         17328, 50118, 36361,  4339,  3660,    30,  4720, 11998, 50118,  1646,\n",
       "          1244,  4149,  3541, 50118,  1646,  1244,  3541, 50118, 23719,  1342,\n",
       "           470,  4149,  3541, 50118,  4310,  8454,  1905,  3541, 50118,  4310,\n",
       "           909,    12,   463,    12,  9830,  3541, 50118, 10993,   496, 12290,\n",
       "          3541, 50118, 44328,    29,   470,  3541, 50118,  1121,  2166, 18947,\n",
       "             6,    10, 11235, 18594, 36418,    16,    41,   364,  7293,   571,\n",
       "          1499, 17407,    30,  6964,  1245, 35512,   396,  1367, 14275,  4682,\n",
       "           583, 12323,     8, 17529,     4, 50118, 21426, 18594,  4003,  9898,\n",
       "           189,   680,    35, 50140,     5, 27121,  1728,  6964,  8391,     8,\n",
       "         15383,  1792,  8391, 45856, 50118,     5, 10602,     8, 30757,  6884,\n",
       "          3569,  6964,  8391,     6, 14065,  2279,   281,     6,     8, 15383,\n",
       "          1792,  8391, 45856,  1437, 50118,     5, 18586,   877,  6964,  8391,\n",
       "             6, 14065,  2279,   281,     6,     8, 15383,  1792,  8391, 45856,\n",
       "          1437, 50118, 50118,   250, 11235, 18594,    16,  2333,  2913,    19,\n",
       "          6964,     8, 15383, 19424,     6,  6122,    15,     5,   191,     8,\n",
       "         36961,     4, 50118,   133,  1385, 11235, 18594,  2147, 45151,    10,\n",
       "          4126,    12,   271,   808,  2147,     6,    61,    16, 13590,    11,\n",
       "          3806,   350,  3841,     7,   323,    10,  6693,     6,    53,    45,\n",
       "          3841,   615,     7,    28,    10, 10348,     4, 50118, 21426,  3807,\n",
       "           293,    32,  2333, 17407,    30,    10,  4126,    12,   271,   808,\n",
       "            50, 19570,  2147,     4, 50118, 40884,  5593,   293,    64,    28,\n",
       "          2673,    11,     5,  1035,     9,    62,     7,  1437,     8,    11,\n",
       "          2608,     9,   159,     7,   479, 50118, 41107,    42,   538, 10175,\n",
       "          2249,     6, 22798,   227,   183,     8,   363,    32,    67,   182,\n",
       "           372,     4, 50118,  1121,   258,     5,   239,  8391,     9, 32150,\n",
       "             8,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[37.5077, -3.9347, 15.3525,  ...,  3.8584,  5.4767, 12.8930],\n",
       "         [ 7.3782, -2.7824, 13.6218,  ...,  4.8712,  5.0904,  8.2832],\n",
       "         [ 1.1484, -3.6915,  7.2563,  ..., -0.1078, -1.0249,  3.4536],\n",
       "         ...,\n",
       "         [ 0.2669, -4.2053,  7.0668,  ..., -5.6054, -5.8515,  2.2009],\n",
       "         [-1.2186, -3.4854, 15.0709,  ...,  2.3310, -3.1703,  4.0132],\n",
       "         [ 8.2976, -3.9727, 28.2076,  ...,  1.5808, -2.9764,  8.9007]]],\n",
       "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
