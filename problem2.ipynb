{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b547d6-486f-4e5f-b69c-9500b7164fb7",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de4f530a-fbdd-4938-8529-26c225f4f608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "22f80913-f18c-4eda-bbd7-fa26d9737b0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "pickle data was truncated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_embeddings_partial_old.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 4\u001b[0m     avg_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: pickle data was truncated"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "with open('avg_embeddings_partial_old.pkl', 'rb') as f:\n",
    "    avg_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bcf937-23b7-4795-9a49-c4e56f4e85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(avg_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "623ae355-b988-4155-9e8a-d6b48ffe8229",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_filepath = \"../home/schen9/glove.6B.300d-vocabulary.txt\"\n",
    "csv_glove_filepath = \"glove.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49658cff-1cb8-4482-9de1-59769d19e057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading from ../home/schen9/glove.6B.300d-vocabulary.txt\n"
     ]
    }
   ],
   "source": [
    "with open(glove_filepath, \"r\", encoding=\"utf-8\") as text_file:\n",
    "    glove_rows = text_file.read().strip().split(\"\\n\")\n",
    "\n",
    "print(f\"Finished reading from {glove_filepath}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c02379d3-a159-4f1c-a7c7-039b154f8896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79b5a6956e64e8183786abb8c92ba77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing to glove.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(csv_glove_filepath, \"w\", encoding=\"utf-8\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"Text\"]) # Header\n",
    "    for i, row in enumerate(tqdm(glove_rows)):\n",
    "        writer.writerow([row.strip()])\n",
    "\n",
    "print(f\"Finished writing to {csv_glove_filepath}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "949f0d61-011b-4fd1-a45f-2fba56e18840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4506bbece1d34197a5cb63914bfb18d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753323714d0d46fbb60b230f55d9a6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/400000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text'],\n",
       "        num_rows: 399997\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "glove_dataset = load_dataset(\"csv\",data_files=csv_glove_filepath) \n",
    "glove_dataset = glove_dataset.filter(lambda x: x[\"Text\"] is not None) # filter out NoneTypes\n",
    "glove_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13045405-e32b-4d98-bc79-a0a46b62b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "transformer_name = \"FacebookAI/roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8214cbc-d472-4b63-9555-21e63b04dcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae6c3b5f04d4cb48e390d50fc4c5ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/399997 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 399997\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"Text\"], truncation=True)\n",
    "\n",
    "batch_size = 50\n",
    "glove_tokens = glove_dataset.map(tokenize, batched=True, batch_size=batch_size)\n",
    "glove_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d264af14-abfb-4f2c-ab66-c3a2e18fa743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>[0, 627, 2]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>[0, 6, 2]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>[0, 4, 2]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>[0, 1116, 2]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>[0, 560, 2]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399992</th>\n",
       "      <td>chanty</td>\n",
       "      <td>[0, 40805, 219, 2]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399993</th>\n",
       "      <td>kronik</td>\n",
       "      <td>[0, 330, 2839, 967, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399994</th>\n",
       "      <td>rolonda</td>\n",
       "      <td>[0, 9396, 11192, 2]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>zsombor</td>\n",
       "      <td>[0, 329, 29, 5223, 368, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>sandberger</td>\n",
       "      <td>[0, 39009, 11178, 2]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399997 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Text                   input_ids      attention_mask\n",
       "0              the                 [0, 627, 2]           [1, 1, 1]\n",
       "1                ,                   [0, 6, 2]           [1, 1, 1]\n",
       "2                .                   [0, 4, 2]           [1, 1, 1]\n",
       "3               of                [0, 1116, 2]           [1, 1, 1]\n",
       "4               to                 [0, 560, 2]           [1, 1, 1]\n",
       "...            ...                         ...                 ...\n",
       "399992      chanty          [0, 40805, 219, 2]        [1, 1, 1, 1]\n",
       "399993      kronik      [0, 330, 2839, 967, 2]     [1, 1, 1, 1, 1]\n",
       "399994     rolonda         [0, 9396, 11192, 2]        [1, 1, 1, 1]\n",
       "399995     zsombor  [0, 329, 29, 5223, 368, 2]  [1, 1, 1, 1, 1, 1]\n",
       "399996  sandberger        [0, 39009, 11178, 2]        [1, 1, 1, 1]\n",
       "\n",
       "[399997 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_df = glove_tokens[\"train\"].to_pandas()\n",
    "glove_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ed1b32e-76f4-4fc4-80e0-d66722262083",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76b92cc3-fd93-4137-8a59-7a778f7d195a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46a22989b8a4f20a38cc1aa7152c8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/399997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for word, t_vector in tqdm(zip(glove_df[\"Text\"], glove_df[\"input_ids\"]), total=len(glove_df)):\n",
    "    embeddings = [avg_embeddings[token].to(device) for token in t_vector if token in avg_embeddings]\n",
    "    w_embedding = torch.empty(embeddings[0].shape[0]).to(device)\n",
    "    for emb in embeddings:\n",
    "        w_embedding = torch.add(w_embedding,emb.to(device))\n",
    "    word_embeddings[word] = torch.div(w_embedding, len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22a248aa-666e-44c6-ab56-8e9993dbafd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_embeddings[6026].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed34e8f7-79d6-4b81-865c-1f7effbbcf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('word_embeddings_partial.pkl', 'wb') as f:\n",
    "    pickle.dump(word_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d9d3d32a-2223-43d0-ae63-4f3fca865ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_similarity(word1,word2,eps=1):\n",
    "    w1_tensor = torch.nan_to_num(word_embeddings[word1])\n",
    "    w2_tensor = torch.nan_to_num(word_embeddings[word2])\n",
    "    w1_tensor = torch.nn.functional.normalize(w1_tensor, p=2, dim=0)\n",
    "    w2_tensor = torch.nn.functional.normalize(w2_tensor, p=2, dim=0)\n",
    "    print(torch.norm(w1_tensor))\n",
    "    print(torch.norm(w2_tensor))\n",
    "    print(w1_tensor)\n",
    "    print(w2_tensor)\n",
    "    return torch.dot(w1_tensor,w2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "de04d89b-0986-41d8-9fe7-576c089b2699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, topn=10):\n",
    "    word_similarities = []\n",
    "    for w in word_embeddings:\n",
    "        if w != word:\n",
    "            word_similarities.append((w,word_similarity(w,word)))\n",
    "    return sorted(word_similarities, key=lambda x: x[1])[:topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "16546110-7c36-4c37-aae1-d3e65f7ad36e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor([0., 0., 0., -0., 0., -0., 0., 0., -0., 0., 0., 0., 0., 0., 0., -0., 0., -0., 0., -0., 0., 0., 0., -0.,\n",
      "        0., 0., -0., 0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., 0., 0., 0., 0., 0.,\n",
      "        -0., -0., 0., 0., 0., 0., -0., -0., 0., 0., 0., 0., 0., 0., 0., -0., 0., -0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., -0., -0., 0., 0., -0., -0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., -0., 0., -0., -0., -0., -0., 0., 0., -0., -0., 0., 0., 0., 0., 0., -0., -0., 0., -0., 0., -0., -0.,\n",
      "        0., 0., -0., -0., -0., 0., -0., 0., 0., -0., -0., -0., 0., -0., 0., -0., 0., 0., -0., -0., 0., -0., 0., -0.,\n",
      "        0., 0., 0., -0., 0., 0., 0., -0., 0., -0., 0., 0., 0., -0., 0., -0., 0., -0., 0., 0., -0., -0., -0., -0.,\n",
      "        -0., -0., 0., -0., 0., -0., -0., -0., 0., 0., -0., 0., -0., 0., 0., 0., 0., 0., -0., 0., -0., 0., 0., -0.,\n",
      "        0., -0., -0., 0., 0., -0., -0., -0., 0., 0., -0., 0., 0., 0., -0., -0., 0., -0., -0., 0., -0., -0., 0., 0.,\n",
      "        -0., -0., 0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., 0., 0., 0., -0., 0., 0.,\n",
      "        0., 0., -0., 0., -0., 0., 0., 0., 0., -0., 0., 0., 0., -0., 0., -0., -0., -0., -0., 0., -0., -0., 0., -0.,\n",
      "        -0., -0., -0., 0., 0., 0., 0., -0., -0., 0., 0., 0., 0., -0., 0., 0., -0., 0., 0., 0., 0., -0., 0., -0.,\n",
      "        -0., -0., -0., 0., -0., 0., 0., -0., -0., -0., 0., -0., -0., 0., -0., -0., 0., 0., 0., 0., -0., -0., -0., 0.,\n",
      "        -0., 0., 0., 0., -0., -0., 0., -0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., -0., 0., -0., 0., 0., 0., -0., -0., -0., -0., -0., -0., 0., 0., -0., -0., 0., -0., -0., 0., 0.,\n",
      "        0., -0., 0., 0., -0., -0., -0., -0., 0., 0., 0., -0., -0., -0., 0., 0., 0., -0., -0., 0., 0., -0., -0., -0.,\n",
      "        -0., -0., 0., 0., -0., -0., -0., -0., 0., -0., 0., -0., 0., 0., 0., -0., 0., -0., 0., -0., 0., -0., 0., -0.,\n",
      "        -0., -0., -0., -0., 0., -0., 0., -0., -0., -0., -0., -0., -0., 0., -0., 0., 0., -0., -0., -0., -0., 0., 0., 0.,\n",
      "        0., -0., 0., 0., -0., -0., -0., 0., -0., -0., 0., -0., -0., 0., 0., -0., 0., -0., 0., -0., -0., -0., 0., 0.,\n",
      "        -0., -0., 0., 0., 0., 0., -0., -0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., 0., 0., 0., -0., 0., 0.,\n",
      "        0., 0., -0., -0., -0., -0., 0., 0., 0., -0., -0., -0., 0., -0., 0., 0., -0., -0., -0., -0., 0., 0., -0., -0.,\n",
      "        0., 0., 0., -0., 0., 0., 0., 0., 0., -0., 0., -0., -0., 0., 0., -0., 0., -0., 0., -0., 0., 0., 0., 0.,\n",
      "        0., 0., -0., 0., 0., 0., -0., 0., -0., -0., -0., 0., -0., -0., -0., 0., 0., 0., 0., -0., -0., -0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., 0., -0., 0., -0., -0., 0., 0., 0., 0., -0., -0.,\n",
      "        -0., 0., 0., 0., -0., 0., 0., -0., 0., 0., -0., -0., 0., 0., -0., 0., 0., -0., 0., 0., 0., 0., -0., -0.,\n",
      "        0., -0., 0., 0., -0., -0., 0., 0., 0., -0., -0., -0., -0., -0., -0., 0., -0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        -0., -0., -0., 0., 0., -0., 0., 0., 0., 0., -0., -0., 0., -0., -0., -0., 0., -0., -0., -0., 0., -0., 0., 0.,\n",
      "        0., 0., -0., 0., -0., 0., 0., 0., 0., -0., -0., -0., -0., 0., -0., -0., 0., -0., -0., 0., 0., 0., 0., 0.,\n",
      "        -0., 0., 0., -0., -0., 0., 0., -0., -0., -0., -0., -0., 0., -0., 0., 0., 0., -0., -0., -0., 0., 0., -0., -0.,\n",
      "        0., 0., 0., 0., -0., -0., -0., 0., -0., 0., -0., 0., 0., -0., 0., -0., -0., -0., -0., 0., 0., 0., -0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., -0., -0., -0., 0., -0., -0., 0., -0., -0., 0., 0., 0., -0., -0., 0., -0., -0., -0.,\n",
      "        -0., 0., 0., -0., 0., -0., -0., -0., -0., -0., -0., 0., -0., 0., -0., 0., -0., 0., 0., 0., -0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([0., 0., 0., -0., 0., -0., 0., 0., -0., 0., 0., 0., 0., 0., 0., -0., 0., -0., 0., -0., 0., 0., 0., -0.,\n",
      "        0., 0., -0., 0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., 0., 0., 0., 0., 0.,\n",
      "        -0., -0., 0., 0., 0., 0., -0., -0., 0., 0., 0., 0., 0., 0., 0., -0., 0., -0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., -0., -0., 0., 0., -0., -0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., -0., 0., -0., -0., -0., -0., 0., 0., -0., -0., 0., 0., 0., 0., 0., -0., -0., 0., -0., 0., -0., -0.,\n",
      "        0., 0., -0., -0., -0., 0., -0., 0., 0., -0., -0., -0., 0., -0., 0., -0., 0., 0., -0., -0., 0., -0., 0., -0.,\n",
      "        0., 0., 0., -0., 0., 0., 0., -0., 0., -0., 0., 0., 0., -0., 0., -0., 0., -0., 0., 0., -0., -0., -0., -0.,\n",
      "        -0., -0., 0., -0., 0., -0., -0., -0., 0., 0., -0., 0., -0., 0., 0., 0., 0., 0., -0., 0., -0., 0., 0., -0.,\n",
      "        0., -0., -0., 0., 0., -0., -0., -0., 0., 0., -0., 0., 0., 0., -0., -0., 0., -0., -0., 0., -0., -0., 0., 0.,\n",
      "        -0., -0., 0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., 0., 0., 0., -0., 0., 0.,\n",
      "        0., 0., -0., 0., -0., 0., 0., 0., 0., -0., 0., 0., 0., -0., 0., -0., -0., -0., -0., 0., -0., -0., 0., -0.,\n",
      "        -0., -0., -0., 0., 0., 0., 0., -0., -0., 0., 0., 0., 0., -0., 0., 0., -0., 0., 0., 0., 0., -0., 0., -0.,\n",
      "        -0., -0., -0., 0., -0., 0., 0., -0., -0., -0., 0., -0., -0., 0., -0., -0., 0., 0., 0., 0., -0., -0., -0., 0.,\n",
      "        -0., 0., 0., 0., -0., -0., 0., -0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., -0., 0., -0., 0., 0., 0., -0., -0., -0., -0., -0., -0., 0., 0., -0., -0., 0., -0., -0., 0., 0.,\n",
      "        0., -0., 0., 0., -0., -0., -0., -0., 0., 0., 0., -0., -0., -0., 0., 0., 0., -0., -0., 0., 0., -0., -0., -0.,\n",
      "        -0., -0., 0., 0., -0., -0., -0., -0., 0., -0., 0., -0., 0., 0., 0., -0., 0., -0., 0., -0., 0., -0., 0., -0.,\n",
      "        -0., -0., -0., -0., 0., -0., 0., -0., -0., -0., -0., -0., -0., 0., -0., 0., 0., -0., -0., -0., -0., 0., 0., 0.,\n",
      "        0., -0., 0., 0., -0., -0., -0., 0., -0., -0., 0., -0., -0., 0., 0., -0., 0., -0., 0., -0., -0., -0., 0., 0.,\n",
      "        -0., -0., 0., 0., 0., 0., -0., -0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., 0., 0., 0., -0., 0., 0.,\n",
      "        0., 0., -0., -0., -0., -0., 0., 0., 0., -0., -0., -0., 0., -0., 0., 0., -0., -0., -0., -0., 0., 0., -0., -0.,\n",
      "        0., 0., 0., -0., 0., 0., 0., 0., 0., -0., 0., -0., -0., 0., 0., -0., 0., -0., 0., -0., 0., 0., 0., 0.,\n",
      "        0., 0., -0., 0., 0., 0., -0., 0., -0., -0., -0., 0., -0., -0., -0., 0., 0., 0., 0., -0., -0., -0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., 0., -0., 0., -0., -0., 0., 0., 0., 0., -0., -0.,\n",
      "        -0., 0., 0., 0., -0., 0., 0., -0., 0., 0., -0., -0., 0., 0., -0., 0., 0., -0., 0., 0., 0., 0., -0., -0.,\n",
      "        0., -0., 0., 0., -0., -0., 0., 0., 0., -0., -0., -0., -0., -0., -0., 0., -0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        -0., -0., -0., 0., 0., -0., 0., 0., 0., 0., -0., -0., 0., -0., -0., -0., 0., -0., -0., -0., 0., -0., 0., 0.,\n",
      "        0., 0., -0., 0., -0., 0., 0., 0., 0., -0., -0., -0., -0., 0., -0., -0., 0., -0., -0., 0., 0., 0., 0., 0.,\n",
      "        -0., 0., 0., -0., -0., 0., 0., -0., -0., -0., -0., -0., 0., -0., 0., 0., 0., -0., -0., -0., 0., 0., -0., -0.,\n",
      "        0., 0., 0., 0., -0., -0., -0., 0., -0., 0., -0., 0., 0., -0., 0., -0., -0., -0., -0., 0., 0., 0., -0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., -0., -0., -0., 0., -0., -0., 0., -0., -0., 0., 0., 0., -0., -0., 0., -0., -0., -0.,\n",
      "        -0., 0., 0., -0., 0., -0., -0., -0., -0., -0., -0., 0., -0., 0., -0., 0., -0., 0., 0., 0., -0., 0., 0., 0.],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity(\"kitty\",\"kitty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "78a427b5-9628-4478-9b11-4489dcc9b558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "Vector 1: tensor([1., 2., 3.], device='cuda:0')\n",
      "Vector 2: tensor([4., 5., 6.], device='cuda:0')\n",
      "Dot Product: tensor(32., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Define two 1D tensors (vectors)\n",
    "vector1 = torch.tensor([1.0, 2.0, 3.0]).to(device) # Shape: [3]\n",
    "vector2 = torch.tensor([4.0, 5.0, 6.0]).to(device)  # Shape: [3]\n",
    "\n",
    "# Compute the dot product\n",
    "dot_product = torch.dot(vector1, vector2)\n",
    "print(type(torch.dot(vector1, vector2)))\n",
    "\n",
    "print(\"Vector 1:\", vector1)\n",
    "print(\"Vector 2:\", vector2)\n",
    "print(\"Dot Product:\", dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "55a2a5f7-e5e1-4cc5-a296-cb91975037c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2673, 0.5345, 0.8018], device='cuda:0')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.normalize(vector1, p=2.0, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "73a2aeba-7ae4-4a02-80c5-f509f1cc80a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: tensor([1., nan, 3., nan, 5.])\n",
      "Cleaned Tensor: tensor([1., 0., 3., 0., 5.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor with NaN values\n",
    "tensor = torch.tensor([1.0, float('nan'), 3.0, float('nan'), 5.0])\n",
    "\n",
    "# Replace NaN values with 0\n",
    "tensor_cleaned = torch.nan_to_num(tensor, nan=0.0)\n",
    "\n",
    "print(\"Original Tensor:\", tensor)\n",
    "print(\"Cleaned Tensor:\", tensor_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef81ea16-265e-492a-b00d-cf8200a7de16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': tensor([ 6.0274e+30, -3.3956e-01,  2.7980e-02, -3.9658e-02,  6.0274e+30,\n",
      "         1.2447e-01,  4.5923e+22,  1.2841e+00,  8.0342e+16,  9.4723e-02,\n",
      "         8.0321e+16,  1.1669e-01,  8.0330e+16, -1.8452e-01,  8.0321e+16,\n",
      "         8.9204e-03,  8.0350e+16, -3.3984e-01,  8.0351e+16, -1.7192e+00,\n",
      "         8.0314e+16,  1.5052e-01,  8.0314e+16,  3.8901e-01,  8.0343e+16,\n",
      "         2.0620e-02,  8.0346e+16,  3.9876e-01,  8.0347e+16,  2.2550e-01,\n",
      "         8.0321e+16,  7.5196e-03,  8.0349e+16,  1.3589e-01,  8.0346e+16,\n",
      "         2.0335e-01,  8.0347e+16,  5.1875e-02,  8.0343e+16,  1.1650e-01,\n",
      "         8.0325e+16,  8.2385e-01,  8.0321e+16, -1.4402e-01,  8.0348e+16,\n",
      "        -5.0784e-02,  8.0341e+16, -1.9922e-01,  8.0349e+16, -4.6669e-01,\n",
      "         8.0343e+16, -2.7125e-01,  8.0343e+16,  5.0448e-01,  8.0348e+16,\n",
      "        -6.6300e-01,  8.0346e+16, -4.4401e-01,  8.0347e+16,  1.9839e-01,\n",
      "         8.0321e+16, -1.0313e+00,  8.0344e+16,  5.9337e-02,  8.0346e+16,\n",
      "         4.6629e-02,  8.0321e+16,  3.8148e-02,  8.0348e+16, -1.6836e-01,\n",
      "         8.0347e+16, -3.8795e-01,  8.0343e+16,  4.9669e-01,  8.0346e+16,\n",
      "         3.6823e-01,  8.0324e+16, -7.2309e+00,  8.0350e+16, -2.6441e-01,\n",
      "         8.0344e+16,  3.1100e-01,  8.0347e+16,  4.1467e-01,  8.0324e+16,\n",
      "         8.2942e-03,  8.0344e+16, -8.1416e-02,  8.0345e+16, -1.3446e-01,\n",
      "         8.0346e+16,  6.9087e-02,  8.0349e+16,  3.8982e-01,  8.0343e+16,\n",
      "        -2.0759e-01,  8.0341e+16,  9.7101e-01,  8.0343e+16,  9.7354e-02,\n",
      "         8.0343e+16, -2.1651e-01,  8.0340e+16, -1.1397e-01,  8.0322e+16,\n",
      "        -7.9279e-01,  8.0338e+16,  1.0362e-01,  8.0343e+16,  6.4801e-02,\n",
      "         8.0349e+16,  2.4636e-01,  8.0348e+16,  2.5296e-02,  8.0322e+16,\n",
      "         9.2411e-02,  8.0341e+16,  6.9368e-01,  8.0325e+16, -6.4319e-01,\n",
      "         8.0321e+16,  5.6392e-02,  8.0344e+16,  1.0068e+00,  8.0345e+16,\n",
      "         4.4364e-01,  8.0346e+16, -2.7571e-01,  8.0349e+16,  2.7214e-02,\n",
      "         8.0343e+16, -1.0246e+00,  8.0341e+16, -4.8140e-01,  8.0343e+16,\n",
      "        -1.2375e-02,  8.0343e+16,  1.9959e-01,  8.0340e+16,  1.1256e-01,\n",
      "         8.0322e+16, -1.0711e-01,  8.0344e+16, -5.5223e-01,  8.0346e+16,\n",
      "        -5.7083e-02,  8.0347e+16, -1.2283e-01,  8.0348e+16,  4.0643e-01,\n",
      "         8.0348e+16,  2.3177e-02,  8.0341e+16, -1.7126e-01,  8.0344e+16,\n",
      "         2.6483e+00,  8.0343e+16, -5.9787e-01,  8.0348e+16,  1.4086e+00,\n",
      "         8.0322e+16,  3.3032e-01,  8.0341e+16, -2.1127e-01,  8.0324e+16,\n",
      "        -8.9606e-02,  8.0325e+16, -7.8835e-02,  8.0321e+16,  3.9303e-02,\n",
      "         8.0348e+16, -1.8168e-02,  8.0346e+16,  3.9086e-02,  8.0348e+16,\n",
      "         1.8638e-01,  8.0342e+16,  5.9673e-01,  8.0345e+16,  5.5708e-02,\n",
      "         8.0330e+16,  2.2263e-01,  8.0345e+16, -4.7091e-01,  8.0343e+16,\n",
      "         1.9583e-01,  8.0346e+16, -2.4095e-02,  8.0324e+16, -2.7700e-01,\n",
      "         8.0344e+16, -8.1351e-03,  8.0345e+16, -2.0876e-01,  8.0346e+16,\n",
      "        -6.2305e-01,  8.0349e+16,  1.1739e-01,  8.0343e+16, -2.3098e-02,\n",
      "         8.0341e+16, -5.8511e-01,  8.0343e+16,  1.2711e-01,  8.0343e+16,\n",
      "         1.2389e-01,  8.0324e+16,  3.0769e-02,  8.0324e+16, -5.3741e-02,\n",
      "         8.0329e+16, -3.1855e-01,  8.0314e+16,  2.5645e-01,  8.0321e+16,\n",
      "         4.0305e-01,  8.0321e+16, -2.5816e+00,  8.0321e+16, -1.6150e+00,\n",
      "         8.0321e+16,  1.5063e-01,  8.0343e+16, -3.9975e-01,  8.0346e+16,\n",
      "         5.9739e-01,  8.0342e+16,  1.7703e-01,  8.0343e+16,  6.6535e-02,\n",
      "         8.0343e+16,  8.3652e-01,  8.0343e+16,  1.4957e-01,  8.0344e+16,\n",
      "        -6.5555e-01,  8.0346e+16, -3.4657e-01,  8.0344e+16,  3.1456e-01,\n",
      "         8.0348e+16,  4.5617e-01,  8.0321e+16,  3.9165e-01,  8.0330e+16,\n",
      "        -3.2133e-01,  8.0321e+16,  5.9502e-01,  8.0340e+16,  1.5380e-01,\n",
      "         8.0342e+16, -1.3066e-01,  8.0349e+16, -2.0900e-01,  8.0344e+16,\n",
      "        -2.0130e-01,  8.0341e+16,  1.2210e-01,  8.0343e+16, -2.0065e-02,\n",
      "         8.0346e+16, -8.2778e-02,  8.0342e+16,  2.6876e-02,  8.0343e+16,\n",
      "         1.9745e-01,  8.0343e+16, -1.4905e-02,  8.0343e+16,  3.6677e-01,\n",
      "         8.0344e+16, -2.4658e-01,  8.0346e+16,  3.1825e-01,  8.0344e+16,\n",
      "         5.6112e-03,  8.0348e+16, -2.0745e-01,  8.0340e+16,  2.6831e-01,\n",
      "         8.0348e+16,  2.8503e-01,  8.0346e+16, -2.6859e-01,  8.0345e+16,\n",
      "         4.7514e-01,  8.0343e+16,  5.3840e-01,  8.0346e+16, -3.0129e-01,\n",
      "         8.0341e+16,  4.1492e-01,  8.0326e+16, -5.9728e-01,  8.0348e+16,\n",
      "         4.0807e-01,  8.0346e+16, -3.6325e-01,  8.0324e+16, -1.3093e+00,\n",
      "         8.0343e+16, -1.2140e-01,  8.0343e+16, -3.2551e-01,  8.0349e+16,\n",
      "         2.2539e-01,  8.0344e+16,  1.1654e-01,  8.0343e+16,  3.3827e-01,\n",
      "         8.0343e+16,  1.2691e-01,  8.0324e+16,  4.1555e-01,  8.0321e+16,\n",
      "         4.6795e-01,  8.0343e+16, -5.9840e-01,  8.0346e+16, -9.5872e-02,\n",
      "         8.0347e+16,  1.0357e-01,  8.0321e+16,  2.6713e-01,  8.0348e+16,\n",
      "         1.5483e-02,  8.0346e+16,  9.8511e-02,  8.0345e+16,  1.2664e+00,\n",
      "         8.0343e+16,  2.6179e+00,  8.0346e+16,  2.1608e-01,  8.0321e+16,\n",
      "        -3.0210e-02,  8.0344e+16, -1.2279e-01,  8.0346e+16, -4.3962e-02,\n",
      "         8.0321e+16,  2.1590e-01,  8.0348e+16,  4.5860e-02,  8.0341e+16,\n",
      "        -1.4189e-01,  8.0349e+16,  3.3213e-01,  8.0343e+16,  1.5424e-02,\n",
      "         8.0343e+16, -9.7212e-02,  8.0348e+16, -4.5462e-01,  8.0346e+16,\n",
      "         7.7863e-01,  8.0347e+16, -2.1192e-01,  8.0321e+16, -1.3238e-01,\n",
      "         8.0344e+16,  1.5353e+00,  8.0343e+16,  1.5912e-01,  8.0321e+16,\n",
      "        -1.4346e-01,  8.0348e+16, -2.8805e-01,  8.0346e+16, -1.0527e-01,\n",
      "         8.0345e+16, -1.0268e-01,  8.0343e+16,  8.9307e-02,  8.0346e+16,\n",
      "        -2.1973e-01,  8.0321e+16,  2.4027e-01,  8.0344e+16, -4.6449e-01,\n",
      "         8.0346e+16, -4.1623e-01,  8.0321e+16, -4.2402e-02,  8.0342e+16,\n",
      "         3.9991e-01,  8.0349e+16,  2.3655e-01,  8.0344e+16, -5.2327e-02,\n",
      "         8.0341e+16, -3.6416e-01,  8.0343e+16, -3.8097e-02,  8.0346e+16,\n",
      "        -1.6669e-02,  8.0342e+16, -3.7701e-01,  8.0343e+16, -2.3657e-01,\n",
      "         8.0343e+16,  1.6669e-02,  8.0343e+16, -4.2484e-02,  8.0344e+16,\n",
      "         1.2948e-01,  8.0346e+16, -4.3513e-02,  8.0344e+16,  1.5216e-01,\n",
      "         8.0348e+16,  4.8139e-01,  8.0341e+16,  1.2920e-01,  8.0314e+16,\n",
      "        -2.0543e-01,  8.0321e+16, -3.9964e-01,  8.0321e+16, -5.2522e-01,\n",
      "         8.0321e+16, -3.7056e-02,  8.0321e+16, -4.1874e-01,  8.0349e+16,\n",
      "        -1.3758e-01,  8.0341e+16, -1.9569e-01,  8.0343e+16,  1.5486e-01,\n",
      "         8.0346e+16,  4.4114e-02,  8.0342e+16, -1.9037e-01,  8.0343e+16,\n",
      "        -3.9510e-01,  8.0343e+16, -1.7000e-01,  8.0343e+16, -3.9105e-01,\n",
      "         8.0344e+16,  2.9079e-01,  8.0346e+16, -1.9594e-01,  8.0344e+16,\n",
      "         1.5869e-01,  8.0321e+16,  1.9438e-01,  8.0330e+16, -2.3343e-01,\n",
      "         8.0321e+16, -3.0572e-01,  8.0348e+16, -8.0817e+00,  8.0346e+16,\n",
      "        -1.7920e-01,  8.0347e+16, -1.9252e-01,  8.0343e+16,  1.2466e-02,\n",
      "         8.0344e+16,  1.4957e-01,  8.0326e+16, -3.2363e-01,  8.0343e+16,\n",
      "        -5.2840e-01,  8.0346e+16,  2.0234e-01,  8.0347e+16,  2.2499e-01,\n",
      "         8.0348e+16, -2.9185e-02,  8.0350e+16, -8.0659e-01,  8.0324e+16,\n",
      "        -1.9362e-01,  8.0343e+16,  1.9997e-01,  8.0346e+16, -3.8532e-02,\n",
      "         8.0342e+16,  2.1725e-01,  8.0343e+16,  3.6085e-02,  8.0343e+16,\n",
      "        -9.8885e-04,  8.0343e+16, -9.4262e-02,  8.0344e+16, -8.3826e-02,\n",
      "         8.0346e+16, -1.4490e-01,  8.0344e+16,  9.9883e-02,  8.0348e+16,\n",
      "         1.0065e-02,  8.0340e+16, -3.8372e-01,  8.0326e+16,  1.0222e-01,\n",
      "         8.0341e+16,  3.2034e-02,  8.0326e+16,  2.8069e-01,  8.0348e+16,\n",
      "         3.3468e-03,  8.0344e+16, -3.0907e-01,  8.0342e+16,  7.9025e-02,\n",
      "         8.0347e+16, -5.7271e-01,  8.0343e+16, -1.7126e-01,  8.0340e+16,\n",
      "         3.6279e-01,  8.0326e+16, -7.7182e-02,  8.0341e+16, -6.7098e-01,\n",
      "         8.0324e+16,  1.8429e-01,  8.0326e+16, -1.3913e-01,  8.0348e+16,\n",
      "         1.0879e-01,  8.0346e+16,  1.6230e-01,  8.0324e+16, -3.1594e-01,\n",
      "         8.0343e+16, -3.9023e-01,  8.0343e+16, -8.5984e-03,  8.0349e+16,\n",
      "         9.9772e-03,  8.0344e+16,  1.2184e-02,  8.0343e+16, -4.5448e-01,\n",
      "         8.0343e+16,  1.4557e-01,  8.0324e+16, -8.3745e-02,  8.0314e+16,\n",
      "         1.1658e-03,  8.0321e+16, -1.1829e-01,  8.0321e+16,  1.6500e-01,\n",
      "         8.0321e+16,  5.9432e+00,  8.0321e+16,  2.2307e-01,  8.0343e+16,\n",
      "         1.5270e-01,  8.0346e+16,  2.2918e-01,  8.0347e+16,  2.4236e-01,\n",
      "         8.0321e+16, -8.7706e-01,  8.0343e+16,  1.5577e-01,  8.0346e+16,\n",
      "        -4.9659e-02,  8.0342e+16,  7.9201e-02,  8.0321e+16, -4.4834e-02,\n",
      "         8.0344e+16,  1.7959e-01,  8.0346e+16,  4.9196e-01,  8.0321e+16,\n",
      "         2.3147e-01,  8.0343e+16, -1.4027e-01,  8.0346e+16,  2.6098e-01,\n",
      "         8.0342e+16,  3.6677e-02,  8.0343e+16,  3.9395e-01,  8.0343e+16,\n",
      "        -2.2936e-01,  8.0343e+16,  2.4253e-01,  8.0344e+16,  1.7953e-01,\n",
      "         8.0346e+16,  3.2190e-01,  8.0344e+16,  4.1229e-01,  8.0348e+16,\n",
      "         1.5461e-01,  8.0329e+16, -8.1033e-02,  8.0314e+16, -3.3031e-01,\n",
      "         8.0321e+16,  4.6857e-01,  8.0321e+16,  2.2290e-01,  8.0321e+16,\n",
      "        -1.0243e-01,  8.0321e+16,  2.2622e-01,  8.0321e+16, -9.9491e-02,\n",
      "         8.0321e+16,  1.2434e+00,  8.0321e+16,  1.4152e-01,  8.0321e+16,\n",
      "        -5.9287e-02,  8.0349e+16,  9.6326e-02,  8.0341e+16,  2.2611e-01,\n",
      "         8.0343e+16, -1.7830e-01,  8.0346e+16,  3.8316e-01,  8.0342e+16,\n",
      "         1.4810e-01,  8.0343e+16,  4.8252e-01,  8.0343e+16, -4.6815e-02,\n",
      "         8.0343e+16,  1.1358e-01,  8.0344e+16,  3.1092e-01,  8.0346e+16,\n",
      "        -2.3549e-01,  8.0344e+16,  1.3644e-01,  8.0321e+16, -2.3428e-02,\n",
      "         8.0330e+16,  7.5855e-02,  8.0321e+16, -5.5645e-02,  8.0348e+16,\n",
      "         2.7145e-01,  8.0346e+16,  3.9936e-01,  8.0347e+16,  2.2773e-01,\n",
      "         8.0343e+16, -4.7178e-02,  8.0344e+16,  4.6951e-01,  8.0326e+16,\n",
      "         8.2767e-01,  8.0342e+16,  2.0707e-01,  8.0343e+16, -1.3346e-01,\n",
      "         8.0343e+16,  7.3105e-02,  8.0324e+16,  2.4044e-01,  8.0349e+16,\n",
      "         3.6553e-01,  8.0341e+16,  1.8029e-01,  8.0343e+16,  2.2263e-01,\n",
      "         8.0346e+16,  2.0353e-01,  8.0342e+16,  1.4692e-01,  8.0343e+16,\n",
      "         1.1796e-01,  8.0343e+16,  7.5778e-01,  8.0343e+16,  2.2915e-01,\n",
      "         8.0344e+16,  1.4604e-01,  8.0346e+16, -4.1145e-02,  8.0344e+16,\n",
      "         5.2569e-02,  8.0325e+16,  8.5588e-02,  8.0343e+16, -3.1456e-01,\n",
      "         8.0346e+16,  5.4381e-03,  8.0342e+16,  5.5084e-01,  8.0326e+16,\n",
      "        -7.5966e-01,  8.0348e+16,  1.8957e-01,  8.0346e+16,  9.2576e-02,\n",
      "         8.0324e+16,  8.7750e-02,  8.0343e+16,  4.0678e-02,  8.0343e+16,\n",
      "        -1.0350e-01,  8.0349e+16,  7.4603e-01,  8.0344e+16, -6.5461e-03,\n",
      "         8.0343e+16, -2.5636e-01,  8.0343e+16, -3.4276e-02,  8.0324e+16,\n",
      "         1.2982e-01,  8.0324e+16,  2.3782e-01,  8.0314e+16, -2.8874e-01,\n",
      "         8.0321e+16, -1.3541e-01,  8.0321e+16, -2.3691e-01,  8.0321e+16,\n",
      "         4.5362e-01,  8.0321e+16, -1.3763e-01,  8.0349e+16, -4.5617e-01,\n",
      "         8.0341e+16, -1.2332e+00,  8.0343e+16, -2.5439e-01,  8.0346e+16,\n",
      "         1.0180e-01,  8.0342e+16,  1.3481e-01,  8.0340e+16, -5.6988e-01,\n",
      "         8.0349e+16, -8.3732e-02,  8.0346e+16,  7.0945e-02,  8.0347e+16,\n",
      "         2.4495e-01,  8.0343e+16, -1.3073e-01,  8.0341e+16,  2.7711e-01,\n",
      "         8.0321e+16, -4.0554e-01,  8.0330e+16,  3.2247e-02,  8.0321e+16,\n",
      "        -3.4879e-02,  8.0348e+16,  7.2968e-02,  8.0346e+16,  1.0777e-01,\n",
      "         8.0347e+16, -1.6650e-01,  8.0343e+16,  4.6859e-01,  8.0344e+16,\n",
      "         3.5694e-02,  8.0326e+16,  1.0171e-01], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(w_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e04d6e-23ec-4fd0-92fc-7ff7c84296ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(\"cactus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b762c7-5b97-4a57-a0f3-85dfa200c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(\"cake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c4129-330d-4799-a24d-dd37eeadaa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(\"angry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d7a920-d813-451c-a735-6d46124150b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(\"quickly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d9f07a-f388-4c40-beb3-7c02acdd893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(\"between\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b48039-ff31-43df-b813-024683cba2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(\"the\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
